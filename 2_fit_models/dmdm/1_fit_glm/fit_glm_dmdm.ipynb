{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fit GLM to dmdm data**\n",
    "---\n",
    "We first fit normal GLM to the dataset. One of differences between our dmdm dataset and IBL dataset is that we have two observations of animal behavior: choice outcome `y` and reaction time `rt`. Here, we fit those two observation independently by simply using two separate GLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **HPC setting**\n",
    "Ashwood's original script is written in python scirpts. Here, we rewrite it in Jupyter to make it more user-friendly to run on HPC with `dask`. [This](https://github.com/pierreglaser/hpc-tutorial/tree/main) is very useful resource to get familiar with `dask`. You can skip these if you are only using one node (which is usually the case when nodes are occupied.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:17: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:17: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:17: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/htcondor.py:6: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import parse_bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://192.168.234.51:8787/status\n"
     ]
    }
   ],
   "source": [
    "# Allocate the computing resources\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "from joblib import Memory, Parallel, delayed, parallel_backend\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    workers=0,      # create the workers \"lazily\" (upon cluster.scal)\n",
    "    memory='32g',   # amount of RAM per worker\n",
    "    processes=1,    # number of execution units per worker (threads and processes)\n",
    "    cores=1,        # among those execution units, number of processes\n",
    "    # a lazy trick to avoid matplotlib crash with parallel plotting\n",
    "    walltime=\"48:00:00\",\n",
    "    worker_extra_args=[\"--resources GPU=1\"], # the only way to add GPUs\n",
    "    local_directory='/nfs/nhome/live/skuroda/jobs', # set your path to save log\n",
    "    log_directory='/nfs/nhome/live/skuroda/jobs' # set your path to save log\n",
    ")   \n",
    "\n",
    "memory = Memory('/nfs/nhome/live/skuroda/joblib-cache') # set your path\n",
    "\n",
    "n = 8\n",
    "cluster.scale(n)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GLM fitting**\n",
    "---\n",
    "At this step, we remove abort trials from the model. Abort trials are hard to predict and often ends up with unstable weights, which is the last thing we want to have. Hence the number of behavioral outcomes: `C = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# ------- load modules -------\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "from glm_utils import fit_glm, fit_glm_runml, fit_RT_glm, \\\n",
    "                      plot_input_vectors, plot_logOR_hit_vs_miss, plot_rt_weights, plot_lls\n",
    "import sys\n",
    "sys.path.insert(0, '../') # a lazy trick to search parent dir\n",
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "from data_io import get_file_dir, load_session_fold_lookup, load_data, load_animal_list\n",
    "from data_labels import create_abort_mask\n",
    "from functools import partial\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup variables -------\n",
    "dname = 'dataAllHumans' # 'dataAllHumans' 'dataAllMiceTraining' \n",
    "num_folds = 5\n",
    "\n",
    "C = 3  # number of output types/categories. Hit/FA/Miss\n",
    "nested_outcome = OrderedDict() # define nested structure for behavioral outcomes\n",
    "nested_outcome[\"Baseline\"] = [2]\n",
    "nested_outcome[\"Change\"] = [0, 1]\n",
    "\n",
    "N_initializations = 10\n",
    "labels_for_plot_y = ['CSize', 'COnset', 'Outcome +1', 'Outcome +2', 'Outcome +3', 'Outcome +4', 'Outcome +5', 'bias']\n",
    "labels_for_plot_rt = ['CSize', 'COnset', \n",
    "                      'PrevHowDeviant?',\n",
    "                      'PrevCOnset', 'PrevRT','bias']\n",
    "labels_for_plot = {'y':labels_for_plot_y, 'rt':labels_for_plot_rt}\n",
    "npr.seed(65)  # set seed in case of randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fit GLM to all animals**\n",
    "---\n",
    "We fit GLMs on both `y` (outcomes) and `rt` (reaction times). In the outcome-predicting GLM, each dependent variables is assumed to be generated from a multinominal distribution. On the other hand, reaction-time-predicting GLM expects dependent variables to follow a gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup path and load data -------\n",
    "data_dir =  get_file_dir().parents[1] / \"data\" / \"dmdm\" / dname / 'data_for_cluster'\n",
    "# Create directory for results:\n",
    "results_dir = get_file_dir().parents[1] / \"results\" / \"dmdm_global_fit\" / dname\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "animal_file = data_dir / 'all_animals_concat.npz'\n",
    "inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(animal_file)\n",
    "session_fold_lookup_table = load_session_fold_lookup(\n",
    "    data_dir / 'all_animals_concat_session_fold_lookup.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GLM_y(inpt_y, y, session, session_fold_lookup_table, results_dir, labels_for_plot, nested_outcome, fold):\n",
    "    # Subset to relevant covariates for covar set of interest:\n",
    "    y = y.astype('int')\n",
    "    figure_directory = results_dir / \"GLM\" / (\"fold_\" + str(fold)) \n",
    "    figure_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Subset to sessions of interest for fold\n",
    "    sessions_to_keep = session_fold_lookup_table[np.where(\n",
    "        session_fold_lookup_table[:, 1] != fold), 0]\n",
    "    idx_this_fold = [\n",
    "        str(sess) in sessions_to_keep for id, sess in enumerate(session)\n",
    "    ]\n",
    "    this_inpt_y, this_y, this_session = inpt_y[idx_this_fold, :], y[\n",
    "        idx_this_fold, :], session[idx_this_fold]\n",
    "    train_size = this_inpt_y.shape[0]\n",
    "\n",
    "    # Identify abort trials for exclusion:\n",
    "    abort_idx = np.where(this_y == 3)[0]\n",
    "    nonviolation_idx, mask = create_abort_mask(abort_idx, this_inpt_y.shape[0])\n",
    "\n",
    "    M = this_inpt_y.shape[1]\n",
    "    loglikelihood_train_vector = []\n",
    "\n",
    "    for iter in range(N_initializations):  # GLM fitting should be\n",
    "        # independent of initialization, so fitting multiple\n",
    "        # initializations is a good way to check that everything is\n",
    "        # working correctly\n",
    "\n",
    "        # Only do this so that errors are avoided - these y values will not\n",
    "        # actually be used for anything (due to violation mask)\n",
    "        this_y[np.where(this_y == 3), :] = 2\n",
    "\n",
    "        loglikelihood_train, recovered_weights, fit_ll = fit_glm([this_inpt_y],\n",
    "                                                                 [this_y], \n",
    "                                                                 M, \n",
    "                                                                 C,\n",
    "                                                                 [mask],\n",
    "                                                                 nested_outcome)\n",
    "        plot_input_vectors(recovered_weights,\n",
    "                           figure_directory,\n",
    "                           title=\"GLM fit; Final LL = \" +\n",
    "                           str(loglikelihood_train),\n",
    "                           save_title='init' + str(iter),\n",
    "                           labels_for_plot=labels_for_plot)\n",
    "        plot_logOR_hit_vs_miss(recovered_weights,\n",
    "                               figure_directory,\n",
    "                               title=\"GLM fit; Final LL = \" +\n",
    "                               str(loglikelihood_train),\n",
    "                               save_title='init' + str(iter),\n",
    "                               labels_for_plot=labels_for_plot)\n",
    "        plot_lls(fit_ll, figure_directory, save_title='y_init' + str(iter))\n",
    "        loglikelihood_train_vector.append(loglikelihood_train)\n",
    "        np.savez(\n",
    "            figure_directory / ('GLM_y_variables_of_interest_iter_' + str(iter) + '.npz'), \n",
    "            loglikelihood_train, recovered_weights)\n",
    "        \n",
    "\n",
    "fit_GLM_y_eachfold = partial(fit_GLM_y, inpt_y, y, session, session_fold_lookup_table, results_dir, labels_for_plot['y'], nested_outcome)        \n",
    "fit_GLM_y_eachfold_cached = memory.cache(fit_GLM_y_eachfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GLM_rt(inpt_rt, rt, stim_onset, y, session, session_fold_lookup_table, results_dir, labels_for_plot, nested_outcome, fold):\n",
    "    # Subset to relevant covariates for covar set of interest:\n",
    "    figure_directory = results_dir / \"GLM\" / (\"fold_\" + str(fold)) \n",
    "    figure_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Subset to sessions of interest for fold\n",
    "    sessions_to_keep = session_fold_lookup_table[np.where(\n",
    "        session_fold_lookup_table[:, 1] != fold), 0]\n",
    "    idx_this_fold = [\n",
    "        str(sess) in sessions_to_keep for id, sess in enumerate(session)\n",
    "    ]\n",
    "    this_inpt_rt, this_rt, this_stim_onset, this_y, this_session = \\\n",
    "          inpt_rt[idx_this_fold, :], rt[idx_this_fold, :], stim_onset[idx_this_fold, :], y[\n",
    "          idx_this_fold, :], session[idx_this_fold]\n",
    "    train_size = this_inpt_rt.shape[0]\n",
    "\n",
    "    # Identify abort trials for exclusion:\n",
    "    abort_idx = np.where(this_y == 3)[0]\n",
    "    nonviolation_idx, mask = create_abort_mask(abort_idx, this_inpt_rt.shape[0])\n",
    "\n",
    "    M = this_inpt_rt.shape[1]\n",
    "    loglikelihood_train_vector = []\n",
    "\n",
    "    for iter in range(N_initializations):  # GLM fitting should be\n",
    "        # independent of initialization, so fitting multiple\n",
    "        # initializations is a good way to check that everything is\n",
    "        # working correctly\n",
    "\n",
    "        loglikelihood_train, recovered_weights, fit_ll = fit_RT_glm([this_inpt_rt],\n",
    "                                                                    [this_rt], \n",
    "                                                                    [this_stim_onset],\n",
    "                                                                    M,\n",
    "                                                                    [mask])\n",
    "        plot_rt_weights(recovered_weights,\n",
    "                           figure_directory,\n",
    "                           title=\"GLM fit; Final LL = \" +\n",
    "                           str(loglikelihood_train),\n",
    "                           save_title='init' + str(iter),\n",
    "                           labels_for_plot=labels_for_plot)\n",
    "        plot_lls(fit_ll, figure_directory, save_title='rt_init' + str(iter))\n",
    "        loglikelihood_train_vector.append(loglikelihood_train)\n",
    "        np.savez(\n",
    "            figure_directory / ('GLM_rt_variables_of_interest_iter_' + str(iter) + '.npz'), \n",
    "            loglikelihood_train, recovered_weights)\n",
    "        \n",
    "fit_GLM_rt_eachfold = partial(fit_GLM_rt, inpt_rt, rt, stim_onset, y, session, session_fold_lookup_table, results_dir, labels_for_plot['rt'], nested_outcome)        \n",
    "fit_GLM_rt_eachfold_cached = memory.cache(fit_GLM_rt_eachfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(cluster) as client: # upload local functions to each worker. They cannot read them with sys.append or sys.insert.\n",
    "    client.wait_for_workers(n)\n",
    "    client.upload_file(str(get_file_dir() / 'data_labels.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   27.8s remaining:   41.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   27.9s remaining:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.1s finished\n",
      "CPU times: user 1.67 s, sys: 466 ms, total: 2.13 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    with parallel_backend('dask', wait_for_workers_timeout=120):\n",
    "        Parallel(verbose=100)(delayed(fit_GLM_y_eachfold)(fold) for fold in range(num_folds))\n",
    "        # Parallel(verbose=100)(delayed(fit_GLM_rt_eachfold)(fold) for fold in range(num_folds))\n",
    "        \n",
    "        # using cached function should improve the performance to some extent...\n",
    "        # I am not using it because it hides the name of ongoing process in Dask's progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n"
     ]
    }
   ],
   "source": [
    "# Once finished, shut down the cluster and the client\n",
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some results for y\n",
    "from IPython.display import Image\n",
    "example_npz_loc = str(results_dir / \"GLM\" / \"fold_4\" / 'GLM_y_variables_of_interest_iter_0.npz')\n",
    "example_npz = np.load(example_npz_loc)\n",
    "example_img_loc = str(results_dir / \"GLM\" / \"fold_4\" / 'y_glm_weights_init0.png')\n",
    "print(example_npz['arr_1'])\n",
    "Image(filename=example_img_loc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fit GLM to each animal separately**\n",
    "---\n",
    "We next fit GLMs to each animal. Each animal's behavior is different from each other, and there is always a chance that GLM weights end up being also different between animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup path and load data -------\n",
    "data_2_dir =  get_file_dir().parents[1] / \"data\" / \"dmdm\" / dname / 'data_for_cluster' / \"data_by_animal\"\n",
    "# Create directory for results:\n",
    "results_2_dir = get_file_dir().parents[1] / \"results\" / \"dmdm_individual_fit\" / dname\n",
    "results_2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "animal_list = load_animal_list(data_2_dir / 'animal_list.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GLM_separately(data_2_dir, results_2_dir, labels_for_plot: dict, nested_outcome, num_folds, animal):\n",
    "    # Fit GLM to data from single animal:\n",
    "    animal_file = data_2_dir / (animal + '_processed.npz')\n",
    "    session_fold_lookup_table = load_session_fold_lookup(\n",
    "        data_2_dir / (animal + '_session_fold_lookup.npz'))\n",
    "    this_results_dir = results_2_dir / animal\n",
    "\n",
    "    # Load data\n",
    "    print(str(animal_file))\n",
    "    inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(animal_file)\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        fit_GLM_y(inpt_y, y, session, session_fold_lookup_table, this_results_dir, labels_for_plot['y'], nested_outcome, fold)\n",
    "        # fit_GLM_rt(inpt_rt, rt, stim_onset, y, session, session_fold_lookup_table, this_results_dir, labels_for_plot['rt'], nested_outcome, fold)\n",
    "            \n",
    "fit_GLM_separately_eachanimal = partial(fit_GLM_separately, data_2_dir, results_2_dir, labels_for_plot, nested_outcome, num_folds)     \n",
    "fit_GLM_separately_eachanimal_cached = memory.cache(fit_GLM_separately_eachanimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(cluster) as client: # upload local functions to each worker. They cannot read them with sys.append or sys.insert.\n",
    "    client.wait_for_workers(n)\n",
    "    client.upload_file(str(get_file_dir() / 'data_io.py'))\n",
    "    client.upload_file(str(get_file_dir() / 'data_labels.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    with parallel_backend('dask', wait_for_workers_timeout=120):\n",
    "        Parallel(verbose=100)(delayed(fit_GLM_separately_eachanimal_cached)(animal) for animal in animal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some results for y\n",
    "from IPython.display import Image\n",
    "example_npz_loc = str(results_2_dir / 'x1108393' / \"GLM\" / \"fold_4\" / 'GLM_y_variables_of_interest_iter_0.npz')\n",
    "example_npz = np.load(example_npz_loc)\n",
    "example_img_loc = str(results_2_dir / 'x1108393' / \"GLM\" / \"fold_4\" / 'y_glm_weights_init0.png')\n",
    "print(example_npz['arr_1'])\n",
    "Image(filename=example_img_loc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once finished, shut down the cluster and the client\n",
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfold_cv import KFoldCV\n",
    "from data_io import load_data, load_session_fold_lookup, load_glmhmm_data, load_cv_arr, get_file_name_for_best_glmhmm_fold, get_best_map_params\n",
    "from data_postprocessing_utils import calculate_state_permutation\n",
    "sys.path.append('../../../3_make_figures/dmdm/')\n",
    "from plot_model_perform import plot_states, plot_model_comparison, plot_state_occupancy\n",
    "import json\n",
    "\n",
    "model = 'GLM_y'\n",
    "print('Animals for individual fitting: {}'.format(animal_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal in animal_list:\n",
    "    print(animal)\n",
    "    this_results_dir = results_2_dir / animal\n",
    "\n",
    "    animal_file = data_2_dir / (animal + '_processed.npz')\n",
    "    session_fold_lookup_table = load_session_fold_lookup(\n",
    "        data_2_dir / (animal + '_session_fold_lookup.npz'))\n",
    "    inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(animal_file)\n",
    "\n",
    "    KFCV = KFoldCV(model, num_folds, results_dir=this_results_dir, animal=animal)\n",
    "    KFCV.save_best_iter(inpt_y, inpt_rt, y, session, rt, stim_onset,\n",
    "                         session_fold_lookup_table, C, outcome_dict=nested_outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
