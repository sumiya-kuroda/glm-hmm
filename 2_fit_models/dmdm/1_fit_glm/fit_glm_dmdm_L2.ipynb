{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fit GLM to dmdm data**\n",
    "---\n",
    "We first fit normal GLM to the dataset. One of differences between our dmdm dataset and IBL dataset is that we have two observations of animal behavior: choice outcome `y` and reaction time `rt`. Here, we fit those two observation independently by simply using two separate GLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **HPC setting**\n",
    "Ashwood's original script is written in python scirpts. Here, we rewrite it in Jupyter to make it more user-friendly to run on HPC with `dask`. [This](https://github.com/pierreglaser/hpc-tutorial/tree/main) is very useful resource to get familiar with `dask`. You can skip these if you are only using one node (which is usually the case when nodes are occupied.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://192.168.234.51:8787/status\n"
     ]
    }
   ],
   "source": [
    "# Allocate the computing resources\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "from joblib import Memory, Parallel, delayed, parallel_backend\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    workers=0,      # create the workers \"lazily\" (upon cluster.scal)\n",
    "    memory='32g',   # amount of RAM per worker\n",
    "    processes=1,    # number of execution units per worker (threads and processes)\n",
    "    cores=1,        # among those execution units, number of processes\n",
    "    # a lazy trick to avoid matplotlib crash with parallel plotting\n",
    "    walltime=\"48:00:00\",\n",
    "    worker_extra_args=[\"--resources GPU=1\"], # the only way to add GPUs\n",
    "    local_directory='/nfs/nhome/live/skuroda/jobs', # set your path to save log\n",
    "    log_directory='/nfs/nhome/live/skuroda/jobs' # set your path to save log\n",
    ")   \n",
    "\n",
    "memory = Memory('/nfs/nhome/live/skuroda/joblib-cache') # set your path\n",
    "\n",
    "n = 4\n",
    "cluster.scale(n)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GLM fitting**\n",
    "---\n",
    "At this step, we remove abort trials from the model. Abort trials are hard to predict and often ends up with unstable weights, which is the last thing we want to have. Hence the number of behavioral outcomes: `C = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# ------- load modules -------\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "from glm_utils import fit_glm, fit_glm_runml, fit_RT_glm, \\\n",
    "                      plot_input_vectors, plot_logOR_hit_vs_miss, plot_rt_weights, plot_lls, plot_logOR_hit_vs_FA\n",
    "import sys\n",
    "sys.path.insert(0, '../') # a lazy trick to search parent dir\n",
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "from data_io import get_file_dir, load_session_fold_lookup, load_data, load_animal_list\n",
    "from data_labels import create_abort_mask\n",
    "from functools import partial\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup variables -------\n",
    "dname = 'dataAllMiceTraining'   # 'dataAllHumans' 'dataAllMiceTraining' \n",
    "num_folds = num_folds_training = num_folds_tuning = 5\n",
    "\n",
    "C = 3  # number of output types/categories. Hit/FA/Miss\n",
    "nested_outcome = OrderedDict() # define nested structure for behavioral outcomes\n",
    "nested_outcome[\"Baseline\"] = [2]\n",
    "nested_outcome[\"Change\"] = [0, 1]\n",
    "ridge_lambda = [0, 0.5, 1, 5, 10, 50, 100] # for ridge regression\n",
    "\n",
    "N_initializations = 10\n",
    "labels_for_plot_y = ['CSize', 'TempExp', 'HzrdBlck', 'PrevHit +1', 'PrevFA +1', 'bias']\n",
    "labels_for_plot_rt = ['CSize', 'COnset', \n",
    "                      'PrevHowDeviant?',\n",
    "                      'PrevCOnset', 'PrevRT','bias']\n",
    "labels_for_plot = {'y':labels_for_plot_y, 'rt':labels_for_plot_rt}\n",
    "regularization = 'L2'\n",
    "npr.seed(65)  # set seed in case of randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fit GLM to all animals**\n",
    "---\n",
    "We fit GLMs on both `y` (outcomes) and `rt` (reaction times). In the outcome-predicting GLM, each dependent variables is assumed to be generated from a multinominal distribution. On the other hand, reaction-time-predicting GLM expects dependent variables to follow a gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup path and load data -------\n",
    "data_dir =  get_file_dir().parents[1] / \"data\" / \"dmdm\" / dname / 'data_for_cluster'\n",
    "# Create directory for results:\n",
    "results_dir = get_file_dir().parents[1] / \"results\" / \"dmdm_global_fit\" / dname\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "animal_file = data_dir / 'all_animals_concat.npz'\n",
    "inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(animal_file)\n",
    "session_fold_lookup_table = load_session_fold_lookup(\n",
    "    data_dir / 'all_animals_concat_session_fold_lookup.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GLM_y(inpt_y, y, session, session_fold_lookup_table, results_dir, labels_for_plot, \n",
    "               nested_outcome, regularization, ridge_lambda, num_folds_tuning, fold):\n",
    "    # Subset to relevant covariates for covar set of interest:\n",
    "    y = y.astype('int')\n",
    "    figure_directory = results_dir / \"GLM\" / (\"fold_\" + str(fold)) \n",
    "    figure_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if regularization is None:\n",
    "        num_folds_tuning = 1\n",
    "\n",
    "    for fold_tuning in range(num_folds_tuning):\n",
    "        # Subset to sessions of interest for fold\n",
    "        if regularization == 'L2':\n",
    "            split_loc = np.logical_and(session_fold_lookup_table[:, 1] != fold, session_fold_lookup_table[:, 2] != fold_tuning)\n",
    "            sessions_to_keep = session_fold_lookup_table[split_loc, 0]\n",
    "        elif regularization is None:\n",
    "            sessions_to_keep = session_fold_lookup_table[np.where(\n",
    "                session_fold_lookup_table[:, 1] != fold), 0]\n",
    "        \n",
    "        idx_this_fold = [\n",
    "            str(sess) in sessions_to_keep for id, sess in enumerate(session)\n",
    "        ]\n",
    "        this_inpt_y, this_y, this_session = inpt_y[idx_this_fold, :], y[\n",
    "            idx_this_fold, :], session[idx_this_fold]\n",
    "        train_size = this_inpt_y.shape[0]\n",
    "\n",
    "        # Identify abort trials for exclusion:\n",
    "        abort_idx = np.where(this_y == 3)[0]\n",
    "        nonviolation_idx, mask = create_abort_mask(abort_idx, this_inpt_y.shape[0])\n",
    "\n",
    "        M = this_inpt_y.shape[1]\n",
    "        loglikelihood_train_vector = []\n",
    "\n",
    "        tuning_directory = figure_directory / (\"foldtuning_\" + str(fold_tuning)) \n",
    "        tuning_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for l2_penalty in ridge_lambda:\n",
    "            for iter in range(N_initializations):  # GLM fitting should be\n",
    "                # independent of initialization, so fitting multiple\n",
    "                # initializations is a good way to check that everything is\n",
    "                # working correctly\n",
    "\n",
    "                # Only do this so that errors are avoided - these y values will not\n",
    "                # actually be used for anything (due to violation mask)\n",
    "                this_y[np.where(this_y == 3), :] = 2\n",
    "\n",
    "                loglikelihood_train, recovered_weights, fit_ll = fit_glm([this_inpt_y], # runml\n",
    "                                                                        [this_y], \n",
    "                                                                        M, \n",
    "                                                                        C,\n",
    "                                                                        [mask],\n",
    "                                                                        nested_outcome,\n",
    "                                                                        regularization=regularization,\n",
    "                                                                        l2_penalty=l2_penalty)\n",
    "                plot_input_vectors(recovered_weights,\n",
    "                                tuning_directory,\n",
    "                                title=\"GLM fit; Final LL = \" +\n",
    "                                str(loglikelihood_train),\n",
    "                                save_title='init' + str(iter) + 'l' + str(l2_penalty),\n",
    "                                labels_for_plot=labels_for_plot)\n",
    "                plot_logOR_hit_vs_miss(recovered_weights,\n",
    "                                    tuning_directory,\n",
    "                                    title=\"GLM fit; Final LL = \" +\n",
    "                                    str(loglikelihood_train),\n",
    "                                    save_title='init' + str(iter) + 'l' + str(l2_penalty),\n",
    "                                    labels_for_plot=labels_for_plot)\n",
    "                plot_logOR_hit_vs_FA(recovered_weights,\n",
    "                                    tuning_directory,\n",
    "                                    title=\"GLM fit; Final LL = \" +\n",
    "                                    str(loglikelihood_train),\n",
    "                                    save_title='init' + str(iter) + 'l' + str(l2_penalty),\n",
    "                                    labels_for_plot=labels_for_plot)\n",
    "\n",
    "                plot_lls(fit_ll, tuning_directory, save_title='y_init' + str(iter) + 'l' + str(l2_penalty))\n",
    "                loglikelihood_train_vector.append(loglikelihood_train)\n",
    "                np.savez(\n",
    "                    tuning_directory / ('GLM_y_variables_of_interest_iter_' + str(iter) + \\\n",
    "                                        '_l' + str(l2_penalty)+ '.npz'), \n",
    "                    loglikelihood_train, recovered_weights)\n",
    "            \n",
    "\n",
    "fit_GLM_y_eachfold = partial(fit_GLM_y, inpt_y, y, session, session_fold_lookup_table, results_dir, labels_for_plot['y'],\n",
    "                              nested_outcome,regularization, ridge_lambda, num_folds_tuning)        \n",
    "fit_GLM_y_eachfold_cached = memory.cache(fit_GLM_y_eachfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(cluster) as client: # upload local functions to each worker. They cannot read them with sys.append or sys.insert.\n",
    "    client.wait_for_workers(n)\n",
    "    client.upload_file(str(get_file_dir() / 'data_labels.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 85.9min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 86.4min remaining: 129.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 86.5min remaining: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 130.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 130.7min finished\n",
      "CPU times: user 6min 35s, sys: 41.1 s, total: 7min 16s\n",
      "Wall time: 2h 10min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    with parallel_backend('dask', wait_for_workers_timeout=120):\n",
    "        Parallel(verbose=100)(delayed(fit_GLM_y_eachfold)(fold) for fold in range(num_folds))\n",
    "        \n",
    "        # using cached function should improve the performance to some extent...\n",
    "        # I am not using it because it hides the name of ongoing process in Dask's progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/dask_jobqueue/core.py:321: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "# Once finished, shut down the cluster and the client\n",
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 parameter hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfold_cv import KFoldCV\n",
    "from data_io import load_data, load_session_fold_lookup, load_glmhmm_data, load_cv_arr, get_file_name_for_best_glmhmm_fold, get_best_map_params\n",
    "from data_postprocessing_utils import calculate_state_permutation\n",
    "sys.path.append('../../../3_make_figures/dmdm/')\n",
    "from plot_model_perform import plot_states, plot_model_comparison, plot_state_occupancy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best iter results for model = GLM_y; fold = 0; num_folds = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24881, 5)\n",
      "(97432, 5)\n",
      "(24881, 5)\n",
      "(97432, 5)\n",
      "(24881, 5)\n",
      "(97432, 5)\n",
      "(24881, 5)\n",
      "(97432, 5)\n",
      "(24881, 5)\n",
      "(97432, 5)\n",
      "(24881, 5)\n",
      "(97432, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:14<00:58, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24881, 5)\n",
      "(97432, 5)\n",
      "(24154, 5)\n",
      "(98159, 5)\n",
      "(24154, 5)\n",
      "(98159, 5)\n",
      "(24154, 5)\n",
      "(98159, 5)\n",
      "(24154, 5)\n",
      "(98159, 5)\n",
      "(24154, 5)\n",
      "(98159, 5)\n",
      "(24154, 5)\n",
      "(98159, 5)\n",
      "(24154, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:27<00:40, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98159, 5)\n",
      "(25009, 5)\n",
      "(97304, 5)\n",
      "(25009, 5)\n",
      "(97304, 5)\n",
      "(25009, 5)\n",
      "(97304, 5)\n",
      "(25009, 5)\n",
      "(97304, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:40<00:26, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25009, 5)\n",
      "(97304, 5)\n",
      "(25009, 5)\n",
      "(97304, 5)\n",
      "(25009, 5)\n",
      "(97304, 5)\n",
      "(23964, 5)\n",
      "(98349, 5)\n",
      "(23964, 5)\n",
      "(98349, 5)\n",
      "(23964, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:55<00:14, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98349, 5)\n",
      "(23964, 5)\n",
      "(98349, 5)\n",
      "(23964, 5)\n",
      "(98349, 5)\n",
      "(23964, 5)\n",
      "(98349, 5)\n",
      "(23964, 5)\n",
      "(98349, 5)\n",
      "(24305, 5)\n",
      "(98008, 5)\n",
      "(24305, 5)\n",
      "(98008, 5)\n",
      "(24305, 5)\n",
      "(98008, 5)\n",
      "(24305, 5)\n",
      "(98008, 5)\n",
      "(24305, 5)\n",
      "(98008, 5)\n",
      "(24305, 5)\n",
      "(98008, 5)\n",
      "(24305, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:08<00:00, 13.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98008, 5)\n",
      "Calculating best L2 parameters...\n",
      "[0.15816259 0.15793576 0.15775197 0.15657726 0.15537008 0.14849962\n",
      " 0.14255741]\n",
      "(0,)\n",
      "Retrieving best iter results for model = GLM_y; fold = 1; num_folds = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25532, 5)\n",
      "(97027, 5)\n",
      "(25532, 5)\n",
      "(97027, 5)\n",
      "(25532, 5)\n",
      "(97027, 5)\n",
      "(25532, 5)\n",
      "(97027, 5)\n",
      "(25532, 5)\n",
      "(97027, 5)\n",
      "(25532, 5)\n",
      "(97027, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:13<00:52, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25532, 5)\n",
      "(97027, 5)\n",
      "(25384, 5)\n",
      "(97175, 5)\n",
      "(25384, 5)\n",
      "(97175, 5)\n",
      "(25384, 5)\n",
      "(97175, 5)\n",
      "(25384, 5)\n",
      "(97175, 5)\n",
      "(25384, 5)\n",
      "(97175, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:26<00:39, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25384, 5)\n",
      "(97175, 5)\n",
      "(25384, 5)\n",
      "(97175, 5)\n",
      "(24760, 5)\n",
      "(97799, 5)\n",
      "(24760, 5)\n",
      "(97799, 5)\n",
      "(24760, 5)\n",
      "(97799, 5)\n",
      "(24760, 5)\n",
      "(97799, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:42<00:28, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24760, 5)\n",
      "(97799, 5)\n",
      "(24760, 5)\n",
      "(97799, 5)\n",
      "(24760, 5)\n",
      "(97799, 5)\n",
      "(23597, 5)\n",
      "(98962, 5)\n",
      "(23597, 5)\n",
      "(98962, 5)\n",
      "(23597, 5)\n",
      "(98962, 5)\n",
      "(23597, 5)\n",
      "(98962, 5)\n",
      "(23597, 5)\n",
      "(98962, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:56<00:14, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23597, 5)\n",
      "(98962, 5)\n",
      "(23597, 5)\n",
      "(98962, 5)\n",
      "(23286, 5)\n",
      "(99273, 5)\n",
      "(23286, 5)\n",
      "(99273, 5)\n",
      "(23286, 5)\n",
      "(99273, 5)\n",
      "(23286, 5)\n",
      "(99273, 5)\n",
      "(23286, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:12<00:00, 14.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99273, 5)\n",
      "(23286, 5)\n",
      "(99273, 5)\n",
      "(23286, 5)\n",
      "(99273, 5)\n",
      "Calculating best L2 parameters...\n",
      "[0.15844515 0.15821207 0.15802335 0.15681838 0.15558214 0.14857927\n",
      " 0.14255464]\n",
      "(0,)\n",
      "Retrieving best iter results for model = GLM_y; fold = 2; num_folds = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25730, 5)\n",
      "(96840, 5)\n",
      "(25730, 5)\n",
      "(96840, 5)\n",
      "(25730, 5)\n",
      "(96840, 5)\n",
      "(25730, 5)\n",
      "(96840, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:13<00:55, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25730, 5)\n",
      "(96840, 5)\n",
      "(25730, 5)\n",
      "(96840, 5)\n",
      "(25730, 5)\n",
      "(96840, 5)\n",
      "(25087, 5)\n",
      "(97483, 5)\n",
      "(25087, 5)\n",
      "(97483, 5)\n",
      "(25087, 5)\n",
      "(97483, 5)\n",
      "(25087, 5)\n",
      "(97483, 5)\n",
      "(25087, 5)\n",
      "(97483, 5)\n",
      "(25087, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:26<00:40, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97483, 5)\n",
      "(25087, 5)\n",
      "(97483, 5)\n",
      "(24963, 5)\n",
      "(97607, 5)\n",
      "(24963, 5)\n",
      "(97607, 5)\n",
      "(24963, 5)\n",
      "(97607, 5)\n",
      "(24963, 5)\n",
      "(97607, 5)\n",
      "(24963, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:39<00:25, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97607, 5)\n",
      "(24963, 5)\n",
      "(97607, 5)\n",
      "(24963, 5)\n",
      "(97607, 5)\n",
      "(23667, 5)\n",
      "(98903, 5)\n",
      "(23667, 5)\n",
      "(98903, 5)\n",
      "(23667, 5)\n",
      "(98903, 5)\n",
      "(23667, 5)\n",
      "(98903, 5)\n",
      "(23667, 5)\n",
      "(98903, 5)\n",
      "(23667, 5)\n",
      "(98903, 5)\n",
      "(23667, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:51<00:12, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98903, 5)\n",
      "(23123, 5)\n",
      "(99447, 5)\n",
      "(23123, 5)\n",
      "(99447, 5)\n",
      "(23123, 5)\n",
      "(99447, 5)\n",
      "(23123, 5)\n",
      "(99447, 5)\n",
      "(23123, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:03<00:00, 12.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99447, 5)\n",
      "(23123, 5)\n",
      "(99447, 5)\n",
      "(23123, 5)\n",
      "(99447, 5)\n",
      "Calculating best L2 parameters...\n",
      "[0.1575055  0.15727521 0.15708753 0.15587857 0.15462763 0.14746109\n",
      " 0.14124663]\n",
      "(0,)\n",
      "Retrieving best iter results for model = GLM_y; fold = 3; num_folds = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25495, 5)\n",
      "(97061, 5)\n",
      "(25495, 5)\n",
      "(97061, 5)\n",
      "(25495, 5)\n",
      "(97061, 5)\n",
      "(25495, 5)\n",
      "(97061, 5)\n",
      "(25495, 5)\n",
      "(97061, 5)\n",
      "(25495, 5)\n",
      "(97061, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:12<00:50, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25495, 5)\n",
      "(97061, 5)\n",
      "(24692, 5)\n",
      "(97864, 5)\n",
      "(24692, 5)\n",
      "(97864, 5)\n",
      "(24692, 5)\n",
      "(97864, 5)\n",
      "(24692, 5)\n",
      "(97864, 5)\n",
      "(24692, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:25<00:37, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97864, 5)\n",
      "(24692, 5)\n",
      "(97864, 5)\n",
      "(24692, 5)\n",
      "(97864, 5)\n",
      "(24911, 5)\n",
      "(97645, 5)\n",
      "(24911, 5)\n",
      "(97645, 5)\n",
      "(24911, 5)\n",
      "(97645, 5)\n",
      "(24911, 5)\n",
      "(97645, 5)\n",
      "(24911, 5)\n",
      "(97645, 5)\n",
      "(24911, 5)\n",
      "(97645, 5)\n",
      "(24911, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:37<00:24, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97645, 5)\n",
      "(24095, 5)\n",
      "(98461, 5)\n",
      "(24095, 5)\n",
      "(98461, 5)\n",
      "(24095, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:49<00:12, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98461, 5)\n",
      "(24095, 5)\n",
      "(98461, 5)\n",
      "(24095, 5)\n",
      "(98461, 5)\n",
      "(24095, 5)\n",
      "(98461, 5)\n",
      "(24095, 5)\n",
      "(98461, 5)\n",
      "(23363, 5)\n",
      "(99193, 5)\n",
      "(23363, 5)\n",
      "(99193, 5)\n",
      "(23363, 5)\n",
      "(99193, 5)\n",
      "(23363, 5)\n",
      "(99193, 5)\n",
      "(23363, 5)\n",
      "(99193, 5)\n",
      "(23363, 5)\n",
      "(99193, 5)\n",
      "(23363, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:02<00:00, 12.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99193, 5)\n",
      "Calculating best L2 parameters...\n",
      "[0.16010783 0.15988597 0.15970595 0.15855306 0.15736639 0.15060722\n",
      " 0.14476039]\n",
      "(0,)\n",
      "Retrieving best iter results for model = GLM_y; fold = 4; num_folds = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26122, 5)\n",
      "(99020, 5)\n",
      "(26122, 5)\n",
      "(99020, 5)\n",
      "(26122, 5)\n",
      "(99020, 5)\n",
      "(26122, 5)\n",
      "(99020, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:13<00:52, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26122, 5)\n",
      "(99020, 5)\n",
      "(26122, 5)\n",
      "(99020, 5)\n",
      "(26122, 5)\n",
      "(99020, 5)\n",
      "(25571, 5)\n",
      "(99571, 5)\n",
      "(25571, 5)\n",
      "(99571, 5)\n",
      "(25571, 5)\n",
      "(99571, 5)\n",
      "(25571, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:26<00:40, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99571, 5)\n",
      "(25571, 5)\n",
      "(99571, 5)\n",
      "(25571, 5)\n",
      "(99571, 5)\n",
      "(25571, 5)\n",
      "(99571, 5)\n",
      "(25021, 5)\n",
      "(100121, 5)\n",
      "(25021, 5)\n",
      "(100121, 5)\n",
      "(25021, 5)\n",
      "(100121, 5)\n",
      "(25021, 5)\n",
      "(100121, 5)\n",
      "(25021, 5)\n",
      "(100121, 5)\n",
      "(25021, 5)\n",
      "(100121, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:42<00:28, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25021, 5)\n",
      "(100121, 5)\n",
      "(24233, 5)\n",
      "(100909, 5)\n",
      "(24233, 5)\n",
      "(100909, 5)\n",
      "(24233, 5)\n",
      "(100909, 5)\n",
      "(24233, 5)\n",
      "(100909, 5)\n",
      "(24233, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:58<00:15, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100909, 5)\n",
      "(24233, 5)\n",
      "(100909, 5)\n",
      "(24233, 5)\n",
      "(100909, 5)\n",
      "(24195, 5)\n",
      "(100947, 5)\n",
      "(24195, 5)\n",
      "(100947, 5)\n",
      "(24195, 5)\n",
      "(100947, 5)\n",
      "(24195, 5)\n",
      "(100947, 5)\n",
      "(24195, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:14<00:00, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100947, 5)\n",
      "(24195, 5)\n",
      "(100947, 5)\n",
      "(24195, 5)\n",
      "(100947, 5)\n",
      "Calculating best L2 parameters...\n",
      "[0.15858716 0.15836562 0.15818556 0.15703031 0.15583932 0.14903737\n",
      " 0.14313403]\n",
      "(0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for fold in range(num_folds_training):\n",
    "    # get best lambda given fold for training\n",
    "\n",
    "    results_dir_thid_fold = results_dir / 'GLM' / ('fold_' + str(fold))\n",
    "\n",
    "    KFCV = KFoldCV('GLM_y', num_folds_tuning, Lambda_vals=ridge_lambda,\n",
    "                   results_dir=results_dir_thid_fold)\n",
    "    out = KFCV.save_best_L2params(inpt_y, inpt_rt, y, session, rt, stim_onset,\n",
    "                                    session_fold_lookup_table, fold, C, \n",
    "                                    outcome_dict=nested_outcome, save_output=True)\n",
    "    \n",
    "    result.append([fold, out[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all the L2 params!\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [3 0]\n",
      " [4 0]]\n"
     ]
    }
   ],
   "source": [
    "np.savez(data_dir / \"best_l2_params_model_GLM_y.npz\", np.array(result))\n",
    "print(\"Saved all the L2 params!\")\n",
    "print(np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l2_params = np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best L2 hyperparameter and fit again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GLM_y_bestL2(inpt_y, y, session, session_fold_lookup_table, results_dir, labels_for_plot, \n",
    "               nested_outcome, best_l2_params, fold):\n",
    "    # Subset to relevant covariates for covar set of interest:\n",
    "    y = y.astype('int')\n",
    "    figure_directory = results_dir / \"GLM\" / (\"fold_\" + str(fold)) \n",
    "\n",
    "    sessions_to_keep = session_fold_lookup_table[np.where(\n",
    "        session_fold_lookup_table[:, 1] != fold), 0]\n",
    "    \n",
    "    idx_this_fold = [\n",
    "        str(sess) in sessions_to_keep for id, sess in enumerate(session)\n",
    "    ]\n",
    "    this_inpt_y, this_y, this_session = inpt_y[idx_this_fold, :], y[\n",
    "        idx_this_fold, :], session[idx_this_fold]\n",
    "    train_size = this_inpt_y.shape[0]\n",
    "\n",
    "    # Identify abort trials for exclusion:\n",
    "    abort_idx = np.where(this_y == 3)[0]\n",
    "    nonviolation_idx, mask = create_abort_mask(abort_idx, this_inpt_y.shape[0])\n",
    "\n",
    "    M = this_inpt_y.shape[1]\n",
    "    loglikelihood_train_vector = []\n",
    "    l2_penalty = best_l2_params[fold,1]\n",
    "\n",
    "    for iter in range(N_initializations):  # GLM fitting should be\n",
    "        # independent of initialization, so fitting multiple\n",
    "        # initializations is a good way to check that everything is\n",
    "        # working correctly\n",
    "\n",
    "        # Only do this so that errors are avoided - these y values will not\n",
    "        # actually be used for anything (due to violation mask)\n",
    "        this_y[np.where(this_y == 3), :] = 2\n",
    "\n",
    "        loglikelihood_train, recovered_weights, fit_ll = fit_glm([this_inpt_y], # runml\n",
    "                                                                [this_y], \n",
    "                                                                M, \n",
    "                                                                C,\n",
    "                                                                [mask],\n",
    "                                                                nested_outcome,\n",
    "                                                                regularization='L2',\n",
    "                                                                l2_penalty=l2_penalty)\n",
    "        plot_input_vectors(recovered_weights,\n",
    "                        figure_directory,\n",
    "                        title=\"GLM fit; Final LL = \" +\n",
    "                        str(loglikelihood_train),\n",
    "                        save_title='init' + str(iter) + 'l' + str(l2_penalty),\n",
    "                        labels_for_plot=labels_for_plot)\n",
    "        plot_logOR_hit_vs_miss(recovered_weights,\n",
    "                            figure_directory,\n",
    "                            title=\"GLM fit; Final LL = \" +\n",
    "                            str(loglikelihood_train),\n",
    "                            save_title='init' + str(iter) + 'l' + str(l2_penalty),\n",
    "                            labels_for_plot=labels_for_plot)\n",
    "        plot_logOR_hit_vs_FA(recovered_weights,\n",
    "                            figure_directory,\n",
    "                            title=\"GLM fit; Final LL = \" +\n",
    "                            str(loglikelihood_train),\n",
    "                            save_title='init' + str(iter) + 'l' + str(l2_penalty),\n",
    "                            labels_for_plot=labels_for_plot)\n",
    "\n",
    "        plot_lls(fit_ll, figure_directory, save_title='y_init' + str(iter) + 'l' + str(l2_penalty))\n",
    "        loglikelihood_train_vector.append(loglikelihood_train)\n",
    "        np.savez(\n",
    "            figure_directory / ('GLM_y_variables_of_interest_iter_' + str(iter) + \\\n",
    "                                '_l' + str(l2_penalty)+ '.npz'), \n",
    "            loglikelihood_train, recovered_weights)\n",
    "            \n",
    "\n",
    "fit_GLM_y_bestL2_eachfold = partial(fit_GLM_y_bestL2, inpt_y, y, session, session_fold_lookup_table, results_dir, labels_for_plot['y'],\n",
    "                              nested_outcome,best_l2_params)        \n",
    "fit_GLM_y_bestL2_eachfold_cached = memory.cache(fit_GLM_y_bestL2_eachfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(cluster) as client: # upload local functions to each worker. They cannot read them with sys.append or sys.insert.\n",
    "    client.wait_for_workers(n)\n",
    "    client.upload_file(str(get_file_dir() / 'data_labels.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  3.4min remaining:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  3.6min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.2min finished\n",
      "CPU times: user 14.5 s, sys: 4.78 s, total: 19.3 s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    with parallel_backend('dask', wait_for_workers_timeout=120):\n",
    "        Parallel(verbose=100)(delayed(fit_GLM_y_bestL2_eachfold_cached)(fold) for fold in range(num_folds))\n",
    "        \n",
    "        # using cached function should improve the performance to some extent...\n",
    "        # I am not using it because it hides the name of ongoing process in Dask's progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once finished, shut down the cluster and the client\n",
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fit GLM to each animal separately**\n",
    "---\n",
    "We next fit GLMs to each animal. Each animal's behavior is different from each other, and there is always a chance that GLM weights end up being also different between animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup path and load data -------\n",
    "data_2_dir =  get_file_dir().parents[1] / \"data\" / \"dmdm\" / dname / 'data_for_cluster' / \"data_by_animal\"\n",
    "# Create directory for results:\n",
    "results_2_dir = get_file_dir().parents[1] / \"results\" / \"dmdm_individual_fit\" / dname\n",
    "results_2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "animal_list = load_animal_list(data_2_dir / 'animal_list.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GLM_separately(data_2_dir, results_2_dir, labels_for_plot: dict, nested_outcome, num_folds, animal):\n",
    "    # Fit GLM to data from single animal:\n",
    "    animal_file = data_2_dir / (animal + '_processed.npz')\n",
    "    session_fold_lookup_table = load_session_fold_lookup(\n",
    "        data_2_dir / (animal + '_session_fold_lookup.npz'))\n",
    "    this_results_dir = results_2_dir / animal\n",
    "\n",
    "    # Load data\n",
    "    print(str(animal_file))\n",
    "    inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(animal_file)\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        fit_GLM_y(inpt_y, y, session, session_fold_lookup_table, this_results_dir, labels_for_plot['y'], nested_outcome, fold)\n",
    "        # fit_GLM_rt(inpt_rt, rt, stim_onset, y, session, session_fold_lookup_table, this_results_dir, labels_for_plot['rt'], nested_outcome, fold)\n",
    "            \n",
    "fit_GLM_separately_eachanimal = partial(fit_GLM_separately, data_2_dir, results_2_dir, labels_for_plot, nested_outcome, num_folds)     \n",
    "fit_GLM_separately_eachanimal_cached = memory.cache(fit_GLM_separately_eachanimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(cluster) as client: # upload local functions to each worker. They cannot read them with sys.append or sys.insert.\n",
    "    client.wait_for_workers(n)\n",
    "    client.upload_file(str(get_file_dir() / 'data_io.py'))\n",
    "    client.upload_file(str(get_file_dir() / 'data_labels.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    with parallel_backend('dask', wait_for_workers_timeout=120):\n",
    "        Parallel(verbose=100)(delayed(fit_GLM_separately_eachanimal_cached)(animal) for animal in animal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once finished, shut down the cluster and the client\n",
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfold_cv import KFoldCV\n",
    "from data_io import load_data, load_session_fold_lookup, load_glmhmm_data, load_cv_arr, get_file_name_for_best_glmhmm_fold, get_best_map_params\n",
    "from data_postprocessing_utils import calculate_state_permutation\n",
    "sys.path.append('../../../3_make_figures/dmdm/')\n",
    "from plot_model_perform import plot_states, plot_model_comparison, plot_state_occupancy\n",
    "import json\n",
    "\n",
    "model = 'GLM_y'\n",
    "print('Animals for individual fitting: {}'.format(animal_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal in animal_list:\n",
    "    print(animal)\n",
    "    this_results_dir = results_2_dir / animal\n",
    "\n",
    "    animal_file = data_2_dir / (animal + '_processed.npz')\n",
    "    session_fold_lookup_table = load_session_fold_lookup(\n",
    "        data_2_dir / (animal + '_session_fold_lookup.npz'))\n",
    "    inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(animal_file)\n",
    "\n",
    "    KFCV = KFoldCV(model, num_folds, results_dir=this_results_dir, animal=animal)\n",
    "    KFCV.save_best_iter(inpt_y, inpt_rt, y, session, rt, stim_onset,\n",
    "                         session_fold_lookup_table, C, outcome_dict=nested_outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
