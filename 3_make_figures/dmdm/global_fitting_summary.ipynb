{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Global fitting summary**\n",
    "---\n",
    "\n",
    "Here we compare the models (again but more in detail and nicely). Some of the process has been already done in GLM-HMM-fitting-Jupyter notebooks, but the main aim of this notebooks is to allow users to do more exploratory analysis. In this particular notebook, we compare the performance of global fitting with two species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nfs/nhome/live/skuroda/.conda/envs/glmhmm/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ssm\n",
    "\n",
    "sys.path.append('../../2_fit_models/dmdm')\n",
    "from data_io import get_file_dir, load_animal_list, load_cv_arr, load_data, get_file_name_for_best_glmhmm_iter, load_session_fold_lookup, load_glmhmm_data\n",
    "from data_labels import create_abort_mask, partition_data_by_session\n",
    "from data_postprocessing_utils import partition_data_by_session\n",
    "from kfold_cv import prepare_data_for_cv\n",
    "from plot_model_perform import create_cv_frame_for_plotting, plot_state_Wk, plot_state_dwelltime, calculate_predictive_accuracy\n",
    "from plotting_utils import load_global_glmhmm_result, calc_dwell_time\n",
    "from plot_animal_behav import plot_PC, plot_CC, plot_FArate\n",
    "import matplotlib.ticker as ticker\n",
    "from plot_model_perform import plot_states, plot_model_comparison, plot_state_Wk_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparision with pred acc.\n",
    "Here we compare the pred acc. betweem different states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup variables -------\n",
    "dnames = ['dataAllHumans', 'dataAllMiceTraining']\n",
    "C = 3  # number of output types/categories\n",
    "D = 1  # data (observations) dimension\n",
    "labels_for_plot_y = ['CSize', 'COnset', 'Outcome +1', 'Outcome +2', 'Outcome +3', 'Outcome +4', 'Outcome +5', 'bias']\n",
    "num_fold = 5\n",
    "global_fit = True\n",
    "transition_alpha = 1 # perform mle => set transition_alpha to 1\n",
    "prior_sigma = 100\n",
    "\n",
    "save_figures = True\n",
    "figure_dir = get_file_dir().parents[1] / 'figures'\n",
    "figure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "K = 4 # max value\n",
    "K_vals = [1, 2, 3, 4]\n",
    "model = 'GLM_HMM_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = dnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  get_file_dir().parents[1] / \"data\" / \"dmdm\" / dname / 'data_for_cluster'\n",
    "results_dir = get_file_dir().parents[1] / \"results\" / \"dmdm_global_fit\" / dname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_y, inpt_rt, y, session, rt, stim_onset = load_data(data_dir / 'all_animals_concat.npz')\n",
    "session_fold_lookup_table = load_session_fold_lookup(\n",
    "    data_dir / 'all_animals_concat_session_fold_lookup.npz')\n",
    "\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir / \"best_init_cvbt_dict_{}.json\".format(model), 'r') as f:\n",
    "    best_init_cvbt_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GLM_HMM_y_K_1/fold_0/alpha_1/sigma_100/lambda_0/fold_tuning_0': 4,\n",
       " 'GLM_HMM_y_K_2/fold_0/alpha_1/sigma_100/lambda_1000000/fold_tuning_0': 9,\n",
       " 'GLM_HMM_y_K_3/fold_0/alpha_1/sigma_100/lambda_1000000/fold_tuning_0': 7,\n",
       " 'GLM_HMM_y_K_4/fold_0/alpha_1/sigma_100/lambda_1000000/fold_tuning_0': 1,\n",
       " 'GLM_HMM_y_K_1/fold_1/alpha_1/sigma_100/lambda_0/fold_tuning_1': 7,\n",
       " 'GLM_HMM_y_K_2/fold_1/alpha_1/sigma_100/lambda_1000000/fold_tuning_1': 5,\n",
       " 'GLM_HMM_y_K_3/fold_1/alpha_1/sigma_100/lambda_1000000/fold_tuning_1': 7,\n",
       " 'GLM_HMM_y_K_4/fold_1/alpha_1/sigma_100/lambda_1000000/fold_tuning_1': 1,\n",
       " 'GLM_HMM_y_K_1/fold_2/alpha_1/sigma_100/lambda_0/fold_tuning_2': 4,\n",
       " 'GLM_HMM_y_K_2/fold_2/alpha_1/sigma_100/lambda_1000000/fold_tuning_2': 6,\n",
       " 'GLM_HMM_y_K_3/fold_2/alpha_1/sigma_100/lambda_1000000/fold_tuning_2': 4,\n",
       " 'GLM_HMM_y_K_4/fold_2/alpha_1/sigma_100/lambda_1000000/fold_tuning_2': 9,\n",
       " 'GLM_HMM_y_K_1/fold_3/alpha_1/sigma_100/lambda_0/fold_tuning_3': 3,\n",
       " 'GLM_HMM_y_K_2/fold_3/alpha_1/sigma_100/lambda_1000000/fold_tuning_3': 9,\n",
       " 'GLM_HMM_y_K_3/fold_3/alpha_1/sigma_100/lambda_1000000/fold_tuning_3': 0,\n",
       " 'GLM_HMM_y_K_4/fold_3/alpha_1/sigma_100/lambda_1000000/fold_tuning_3': 1,\n",
       " 'GLM_HMM_y_K_1/fold_4/alpha_1/sigma_100/lambda_0/fold_tuning_4': 4,\n",
       " 'GLM_HMM_y_K_2/fold_4/alpha_1/sigma_100/lambda_1000000/fold_tuning_4': 6,\n",
       " 'GLM_HMM_y_K_3/fold_4/alpha_1/sigma_100/lambda_1000000/fold_tuning_4': 2,\n",
       " 'GLM_HMM_y_K_4/fold_4/alpha_1/sigma_100/lambda_1000000/fold_tuning_4': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_init_cvbt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'GLM_HMM_y_K_1/fold_0/alpha_1/sigma_100'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3889409/1829566381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     raw_files = get_file_name_for_best_glmhmm_iter(K, results_dir,\n\u001b[1;32m     14\u001b[0m                                                     \u001b[0mbest_init_cvbt_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                                     'GLM_HMM_y_raw_parameters_itr_')\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mthis_hmm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_glmhmm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workstation2023/glm-hmm/2_fit_models/dmdm/data_io.py\u001b[0m in \u001b[0;36mget_file_name_for_best_glmhmm_iter\u001b[0;34m(K, overall_dir, best_init_cvbt_dict, model, fname_header, global_fit, num_fold)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mkey_for_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_K_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/fold_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                             \u001b[0;34m+\u001b[0m \u001b[0;34m'/alpha_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/sigma_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mbest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_init_cvbt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_for_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mfname_tail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_a'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_s'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GLM_HMM_y_K_1/fold_0/alpha_1/sigma_100'"
     ]
    }
   ],
   "source": [
    "# cvbt_folds_model = load_cv_arr(results_dir / \"cvbt_folds_model_{}.npz\".format(model))\n",
    "# cvbt_train_folds_model = load_cv_arr(results_dir / \"cvbt_train_folds_model_{}.npz\".format(model))\n",
    "\n",
    "cvpa_folds_model = np.zeros((1, 1, len(K_vals), num_fold))\n",
    "cvpa_train_folds_model = np.zeros((1, 1, len(K_vals), num_fold))\n",
    "for model_idx, K in enumerate(K_vals):\n",
    "    print(\"K = \" + str(K))\n",
    "    with open(results_dir / \"best_init_cvbt_dict_{}.json\".format(model), 'r') as f:\n",
    "        best_init_cvbt_dict = json.load(f)\n",
    "\n",
    "    # Get the file name corresponding to the best initialization for\n",
    "    # each training fold for given K value\n",
    "    raw_files = get_file_name_for_best_glmhmm_iter(K, results_dir,\n",
    "                                                    best_init_cvbt_dict, model, \n",
    "                                                    'GLM_HMM_y_raw_parameters_itr_')\n",
    "    for fold in range(num_fold):\n",
    "        this_hmm_params, _, _, _, _= load_glmhmm_data(raw_files[fold])\n",
    "        \n",
    "        # prepare the dataset\n",
    "        test_data, train_data, M_y, M_rt, n_test, n_train = \\\n",
    "        prepare_data_for_cv(inpt_y, inpt_rt, y, session, rt, stim_onset, \n",
    "                            session_fold_lookup_table, fold,\n",
    "                            paramter_tuning=False)\n",
    "\n",
    "        [test_inpt_y, test_inpt_rt, test_y, test_rt, test_stim_onset, test_mask, test_session] = test_data\n",
    "        [train_inpt_y, train_inpt_rt, train_y, train_rt, train_stim_onset, train_mask, train_session] = train_data\n",
    "\n",
    "        test_inpt_y = np.hstack((test_inpt_y, np.ones((len(test_inpt_y), 1))))\n",
    "        train_inpt_y = np.hstack((train_inpt_y, np.ones((len(train_inpt_y), 1))))\n",
    "\n",
    "        # For GLM-HMM set values of y for violations to 2.  This value doesn't\n",
    "        # matter (as mask will ensure that these y values do not contribute to\n",
    "        # loglikelihood calculation\n",
    "        test_y[np.where(test_mask == 0)[0], :] = 2\n",
    "        train_y[np.where(train_mask == 0)[0], :] = 2\n",
    "\n",
    "        # For GLM-HMM, need to partition data by session\n",
    "        this_test_inputs, this_test_datas, this_test_masks = \\\n",
    "            partition_data_by_session(\n",
    "                test_inpt_y, test_y,\n",
    "                test_mask,\n",
    "                test_session)\n",
    "        this_train_inputs, this_train_datas, this_train_masks = \\\n",
    "            partition_data_by_session(\n",
    "                train_inpt_y, train_y,\n",
    "                train_mask,\n",
    "                train_session)   \n",
    "\n",
    "        # Calculate permutation\n",
    "        # init_state_dist, log_transition_matrix, weight_vectors, permutation = \\\n",
    "        #     calculate_state_permutation(hmm_params, K)\n",
    "\n",
    "        this_hmm = ssm.HMM(K,\n",
    "                        D,\n",
    "                        M_y,\n",
    "                        observations=\"input_driven_obs_multinominal\",\n",
    "                        observation_kwargs=dict(C=C, prior_sigma=prior_sigma),\n",
    "                        transitions=\"standard\")\n",
    "        # transition_kwargs=dict(alpha=transition_alpha, kappa=0)\n",
    "\n",
    "        if K ==1:\n",
    "            this_hmm.observations.params = this_hmm_params\n",
    "        elif K > 1:\n",
    "            this_hmm.params = this_hmm_params\n",
    "            \n",
    "        predictive_acc_train = calculate_predictive_accuracy(this_train_inputs, \n",
    "                                                               this_train_datas, \n",
    "                                                               this_train_masks, \n",
    "                                                               this_hmm, \n",
    "                                                               train_y, \n",
    "                                                               np.where(train_mask)[0])\n",
    "\n",
    "        predictive_acc_test = calculate_predictive_accuracy(this_test_inputs, \n",
    "                                                               this_test_datas, \n",
    "                                                               this_test_masks, \n",
    "                                                               this_hmm, \n",
    "                                                               test_y, \n",
    "                                                               np.where(test_mask)[0])\n",
    "\n",
    "        cvpa_folds_model[:, :, model_idx, fold] = predictive_acc_test\n",
    "        cvpa_train_folds_model[:, :, model_idx, fold] = predictive_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_comparison(cvpa_folds_model,\n",
    "                      cvpa_train_folds_model,\n",
    "                      global_fit,\n",
    "                      K_vals,\n",
    "                      figure_dir, 'Pred. Acc. ', 'Pred_acc',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- setup variables -------\n",
    "dnames = ['dataAllHumans'] # , 'dataAllMiceTraining'\n",
    "C = 3  # number of output types/categories\n",
    "D = 1  # data (observations) dimension\n",
    "labels_for_plot_y = ['CSize', 'COnset', 'Outcome +1', 'Outcome +2', 'Outcome +3', 'Outcome +4', 'Outcome +5', 'bias']\n",
    "\n",
    "save_figures = True\n",
    "figure_dir = get_file_dir().parents[1] / 'figures'\n",
    "figure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "K = 2 # 4\n",
    "model = 'GLM_HMM_y'\n",
    "regularization = 'L2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname in dnames:\n",
    "\n",
    "    data_dir =  get_file_dir().parents[1] / \"data\" / \"dmdm\" / dname / 'data_for_cluster'\n",
    "    # results_dir = get_file_dir().parents[1] / \"results\" / \"dmdm_global_fit\" / dname\n",
    "\n",
    "    states_max_posterior, _, inpt_rt, _, session, _, _, mask, hmm_params \\\n",
    "        = load_global_glmhmm_result(K, model, data_dir, regularization)\n",
    "\n",
    "    inpt_y, _, y, _, rt, stim_onset = load_data(data_dir / 'all_animals_concat_unnormalized.npz')\n",
    "\n",
    "    data = {'session': session,\n",
    "            'fitted_trials': np.squeeze(mask),\n",
    "            'state': states_max_posterior,\n",
    "            'early_report': np.squeeze(y) == 2, # .astype(int)\n",
    "            'hit': np.squeeze(y) == 1,\n",
    "            'miss': np.squeeze(y) == 0,\n",
    "            'abort': np.squeeze(y) == 3,\n",
    "            'sig': inpt_y[:,0],\n",
    "            'rt_change': np.squeeze(rt) - np.squeeze(stim_onset),\n",
    "            }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_all = pd.DataFrame(data)\n",
    "\n",
    "    fig = plt.figure(constrained_layout = True, figsize=(40/2.54, 4.25/2.54 * K))\n",
    "    fig.suptitle('GLM_HMM_y: global {}'.format(dname))\n",
    "\n",
    "    # create 3x1 subfigs\n",
    "    subfigs = fig.subfigures(nrows=K, ncols=1)\n",
    "    for row, subfig in enumerate(subfigs):\n",
    "        zk = row\n",
    "        subfig.suptitle('State Zk = {}'.format(zk))\n",
    "\n",
    "        # create 1x3 subplots per subfig\n",
    "        axs = subfig.subplots(nrows=1, ncols=7)\n",
    "\n",
    "        # Plot Psychometric/Chronomteric Curve and False Alarm Rate\n",
    "        plot_PC(df_all, axs[0], label='test data', K=zk)\n",
    "        axs[0].set_xlabel('Change magnitude \\n (octaves)')\n",
    "        axs[0].set_ylabel('Proportion hits')\n",
    "        axs[0].set_ylim(0, 1)\n",
    "        axs[0].set_xlim(0, 2)\n",
    "        axs[0].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "        axs[0].xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "        plot_CC(df_all, axs[1], label='test data', K=zk)\n",
    "        axs[1].set_xlabel('Change magnitude \\n (octaves)')\n",
    "        axs[1].set_ylabel('Reaction time (s)')\n",
    "        axs[1].axis('tight')\n",
    "        axs[1].set_xlim(0, 2)\n",
    "        axs[1].set_ylim(0, 1.5)\n",
    "        axs[1].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "        axs[1].xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "        plot_FArate(df_all, axs[2], label='test data', K=zk)\n",
    "        axs[2].set_xlabel('Total')\n",
    "        axs[2].set_ylabel('Early report rate')\n",
    "        axs[2].axis('tight')\n",
    "        axs[2].set_xlim(-1, 1)\n",
    "        axs[2].set_ylim(0, 0.5)\n",
    "        axs[2].xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "        # Plot GLM weights\n",
    "        weight_vectors = hmm_params[2][zk]\n",
    "        plot_state_Wk_diff(weight_vectors,axs[3])\n",
    "        # axs[3].set_xlabel('Covariate')\n",
    "        axs[3].set_ylabel('Weight')\n",
    "        axs[3].legend(bbox_to_anchor=(1, 1.35), \n",
    "                    ncol=3,\n",
    "                    fontsize=5,\n",
    "                    labelspacing=0.05,\n",
    "                    framealpha=0,\n",
    "                    markerscale=0)\n",
    "        axs[3].axis('tight')\n",
    "        axs[3].set_xticks(list(range(0, len(labels_for_plot_y))))\n",
    "        axs[3].set_xticklabels(list(range(0, len(labels_for_plot_y))),\n",
    "                            rotation=90)\n",
    "        axs[3].set_xlim(-1, hmm_params[2][zk].shape[1])\n",
    "        axs[3].set_ylim(-7, 7)\n",
    "\n",
    "        # Plot dwell time\n",
    "        dwell_across_sessions = calc_dwell_time(df_all)\n",
    "        dwell_time_df = dwell_across_sessions[dwell_across_sessions['state'] == zk]\n",
    "        plot_state_dwelltime(dwell_time_df, axs[4])\n",
    "        axs[4].set_ylabel('# State changes')\n",
    "        axs[4].set_xlabel(\"Dwell time \\n (# trials)\")\n",
    "        axs[4].set_ylim(0, 25)\n",
    "        axs[4].set_xlim(0, 80)\n",
    "        axs[4].yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "        axs[4].xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        \n",
    "    sns.despine(fig, offset=3, trim=False)\n",
    "\n",
    "    if save_figures:\n",
    "        fig.savefig(figure_dir / 'fig_state_summary_global_{}_NumState_{}.pdf'.format(dname, str(K)))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider abort states_max_posterior nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_y_inpt, master_y, master_session, master_rt, master_stim_onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each animal\n",
    "for animal in animal_list:\n",
    "\n",
    "    # Generate figure\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1,\n",
    "                        right=0.95,\n",
    "                        top=0.95,\n",
    "                        wspace=0.45,\n",
    "                        hspace=0.6)\n",
    "    ax1= plt.subplot() \n",
    "\n",
    "    # Plot normalized LL\n",
    "    cols = ['#999999', '#984ea3', '#e41a1c', '#dede00']\n",
    "\n",
    "    this_results_dir = results_2_dir / animal\n",
    "    cv_arr_GLM_y = load_cv_arr(this_results_dir / \"cvbt_folds_model_GLM_y.npz\")\n",
    "    df_GLM_y, _, _ = create_cv_frame_for_plotting(cv_arr_GLM_y)\n",
    "    df_GLM_y['model'] = -1\n",
    "    cv_arr_GLM_HMM_y = load_cv_arr(this_results_dir / \"cvbt_folds_model_GLM_HMM_y.npz\")\n",
    "    df_GLM_HMM_y, _, _ = create_cv_frame_for_plotting(cv_arr_GLM_HMM_y)\n",
    "    df_test = pd.concat([df_GLM_y, df_GLM_HMM_y])\n",
    "    df_test['label'] = 'test'\n",
    "\n",
    "    cv_train_arr_GLM_y = load_cv_arr(this_results_dir / \"cvbt_train_folds_model_GLM_y.npz\")\n",
    "    df_train_GLM_y, _, _ = create_cv_frame_for_plotting(cv_train_arr_GLM_y)\n",
    "    df_train_GLM_y['model'] = -1\n",
    "    cv_train_arr_GLM_HMM_y = load_cv_arr(this_results_dir / \"cvbt_train_folds_model_GLM_HMM_y.npz\")\n",
    "    df_train_GLM_HMM_y, _, _ = create_cv_frame_for_plotting(cv_train_arr_GLM_HMM_y)\n",
    "    df_train = pd.concat([df_train_GLM_y, df_train_GLM_HMM_y])\n",
    "    df_train['label'] = 'training'\n",
    "\n",
    "    df_all = pd.concat([df_test, df_train])\n",
    "\n",
    "    y_min = df_train.groupby('model')['cv_bit_trial'].min()[-1]\n",
    "    df_all['cv_bit_trial'] = df_all['cv_bit_trial'] - y_min\n",
    "\n",
    "    xrange = [-1, 0, 1, 2, 3, 4]\n",
    "    meanst = df_all.groupby(['model','label'], as_index=False).agg({'cv_bit_trial': 'mean'})\n",
    "    sdt = df_all.groupby(['model','label'], as_index=False).agg({'cv_bit_trial': 'std'})\n",
    "    sns.lineplot(data=df_all, x=\"model\", y=\"cv_bit_trial\", hue=\"label\")\n",
    "\n",
    "    plt.xticks([-1, 0, 1, 2, 3, 4], ['GLM', '1', '2', '3', '4', '5'],\n",
    "                fontsize=10)\n",
    "    plt.ylabel(\"$\\Delta$ test LL (bits/trial)\", fontsize=10, labelpad=0)\n",
    "    plt.xlabel(\"# states\", fontsize=10, labelpad=0)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.ylim((-0.01, 0.24))\n",
    "    # plt.yticks(color = cols[0])\n",
    "    leg = plt.legend(fontsize=10,\n",
    "                        labelspacing=0.05,\n",
    "                        handlelength=1.4,\n",
    "                        borderaxespad=0.05,\n",
    "                        borderpad=0.05,\n",
    "                        framealpha=0,\n",
    "                        bbox_to_anchor=(1.2, 0.90),\n",
    "                        loc='lower right',\n",
    "                        markerscale=0)\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(1.0)\n",
    "\n",
    "    fig.suptitle('GLM_HMM_y LL: {}'.format(animal))\n",
    "\n",
    "    if save_figures:\n",
    "        fig.savefig(figure_dir / 'fig_nll_{}.pdf'.format(animal))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
